{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annien094/PINNs-tutorial-MICCAI-2024/blob/main/PINNs_AP2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBx2-sTPXl33"
      },
      "source": [
        "**Welcome to the second part of the PINNs tutorial!**\n",
        "\n",
        "In this notebook, we will set up a PINN to solve the Aliev-Panfilov model that describes the electrical potential propagation in the heart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow--mP73X5q9"
      },
      "source": [
        "## Set up: install and import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiaHOqJqw8m8",
        "outputId": "7aa37362-0df0-4517-f4e1-baeaad40745d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks\n",
            "Requirement already satisfied: tensorflow==2.17 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.17) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow==2.17) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17) (0.1.2)\n",
            "Requirement already satisfied: tensorflow-probability==0.24 in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.24) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.24) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.24) (1.26.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.24) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.24) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.24) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.24) (0.1.8)\n",
            "Requirement already satisfied: tf-keras==2.17 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tf-keras==2.17) (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras==2.17) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras==2.17) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras==2.17) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras==2.17) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras==2.17) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras==2.17) (0.1.2)\n",
            "Collecting deepxde==1.12.1\n",
            "  Downloading DeepXDE-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from deepxde==1.12.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepxde==1.12.1) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepxde==1.12.1) (1.5.2)\n",
            "Collecting scikit-optimize>=0.9.0 (from deepxde==1.12.1)\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deepxde==1.12.1) (1.13.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize>=0.9.0->deepxde==1.12.1) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize>=0.9.0->deepxde==1.12.1)\n",
            "  Downloading pyaml-24.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize>=0.9.0->deepxde==1.12.1) (24.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepxde==1.12.1) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde==1.12.1) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde==1.12.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde==1.12.1) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde==1.12.1) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde==1.12.1) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde==1.12.1) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->deepxde==1.12.1) (2.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize>=0.9.0->deepxde==1.12.1) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->deepxde==1.12.1) (1.16.0)\n",
            "Downloading DeepXDE-1.12.1-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-24.9.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize, deepxde\n",
            "Successfully installed deepxde-1.12.1 pyaml-24.9.0 scikit-optimize-0.10.2\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "Successfully installed matplotlib-3.9.2\n",
            "No backend selected.\n",
            "Finding available backend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: tensorflow.compat.v1\n",
            "Other supported backends: tensorflow, pytorch, jax, paddle.\n",
            "paddle supports more examples now and is recommended.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found tensorflow.compat.v1\n",
            "Setting the default backend to \"tensorflow.compat.v1\". You can change it in the ~/.deepxde/config.json file or export the DDE_BACKEND environment variable. Valid options are: tensorflow.compat.v1, tensorflow, pytorch, jax, paddle (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Enable just-in-time compilation with XLA.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "%cd /content/drive/MyDrive/Colab Notebooks\n",
        "\n",
        "# Setup\n",
        "# Note: running on a CPU is sufficient for this tutorial\n",
        "!pip install --upgrade tensorflow==2.17\n",
        "!pip install --upgrade tensorflow-probability==0.24\n",
        "!pip install --upgrade tf-keras==2.17\n",
        "!pip install --upgrade deepxde==1.12.1\n",
        "#!pip install --upgrade numpy\n",
        "!pip install --upgrade matplotlib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import deepxde as dde #1.12.0\n",
        "from deepxde.backend import tensorflow\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "# module load cuda if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U325ZtoMar4B"
      },
      "source": [
        "## PINNs setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv7Z9TJgYC63"
      },
      "source": [
        "First, let's set up the hyperparameters of the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_TuMC95Ow8m9"
      },
      "outputs": [],
      "source": [
        "# Training Parameters\n",
        "num_domain = 20000 # number of training points within the domain\n",
        "num_boundary = 1000 # number of training boundary condition points on the geometry boundary\n",
        "num_test = 1000 # number of testing points within the domain\n",
        "MAX_MODEL_INIT = 5 # maximum number of times allowed to initialize the model\n",
        "MAX_LOSS = 0.1 # upper limit to the initialized loss\n",
        "epochs_init = 15000 # number of epochs for training initial phase\n",
        "epochs_main =400000 # number of epochs for main training phase\n",
        "lr = 0.0005 # learning rate\n",
        "test_size = 0.9 # split, fraction saved for test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nu4silIa04W"
      },
      "source": [
        "Let's also set the parameters for the Aliev Panfilov model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ekwJHVvBw8m9"
      },
      "outputs": [],
      "source": [
        "# Aliev Panfilov model parameters\n",
        "a = 0.01\n",
        "b = 0.15\n",
        "D = 0.1\n",
        "k = 8.0\n",
        "mu_1 = 0.2\n",
        "mu_2 = 0.3\n",
        "epsilon = 0.002"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_56fTsq3a_cb"
      },
      "source": [
        "Now, we load the training data, which was generated using a FD solver in Matlab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQpPvtZGw8m9",
        "outputId": "b24cb0f5-e9d2-47ee-ccb2-0d210f730823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "# GT data loading\n",
        "file_name = \"APdata.mat\"\n",
        "!pwd\n",
        "data = scipy.io.loadmat(file_name,squeeze_me=True)\n",
        "\n",
        "tlin, xlin, ylin, vlin, Vsav, o_in, v_in, wlin = data[\"tlin\"], data[\"xlin\"], data[\"ylin\"], data[\"vlin\"], data[\"Vsav\"], data[\"observe_in\"], data[\"v_in\"], data[\"wlin\"]\n",
        "\n",
        "max_t = np.max(tlin)\n",
        "max_x = np.max(xlin)\n",
        "max_y = np.max(ylin)\n",
        "min_t = np.min(tlin)\n",
        "min_x = np.min(xlin)\n",
        "min_y = np.min(ylin)\n",
        "X = xlin.reshape(-1, 1)\n",
        "Y = ylin.reshape(-1, 1)\n",
        "T = tlin.reshape(-1, 1)\n",
        "V = vlin.reshape(-1, 1)\n",
        "W = wlin.reshape(-1, 1)\n",
        "spacing = xlin[1]-xlin[0]\n",
        "\n",
        "observe_x = np.hstack((X, Y, T))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYHsFqWcYY-V"
      },
      "source": [
        "**Exercise**: define a function called pde that takes the network's input x and output y input, and return the residual between the network's predictions and the equations.\n",
        "\n",
        "The Aliev-Panfilov equations are as follows:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial V}{\\partial t} = \\nabla \\cdot (D \\nabla V) - kV (V - a) (V - 1) - VW\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{dW}{dt} = \\left( \\epsilon + \\frac{\\mu_1 W}{V + \\mu_2} \\right) \\left( -W - kV (V - b - 1) \\right).\n",
        "$$\n",
        "\n",
        "V(x,y,t) is the transmembrane potential, for which we have some experimental data. W(x,y,t) is a latent variable that is not measurable. We will solve the coupled systems for both variables in this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f58RG3rtaLq_"
      },
      "outputs": [],
      "source": [
        "# Complete the unfinished code\n",
        "def pde(x, y):\n",
        "\n",
        "    V, W = y[:, 0:1], y[:, 1:2]\n",
        "\n",
        "    dv_dt = #...\n",
        "    dv_dxx = #...\n",
        "    dv_dyy = #...\n",
        "    dw_dt = #...\n",
        "\n",
        "    eq_a = #...\n",
        "    eq_b = #...\n",
        "    return [eq_a, eq_b]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HxRbtc6iw8m9"
      },
      "outputs": [],
      "source": [
        "# @title Solution\n",
        "def pde(x, y):\n",
        "\n",
        "    V, W = y[:, 0:1], y[:, 1:2]\n",
        "#\n",
        "    dv_dt = dde.grad.jacobian(y, x, i=0, j=2)\n",
        "    dv_dxx = dde.grad.hessian(y, x, component=0, i=0, j=0)\n",
        "    dv_dyy = dde.grad.hessian(y, x, component=0, i=1, j=1)\n",
        "    dw_dt = dde.grad.jacobian(y, x, i=1, j=2)\n",
        "\n",
        "    eq_a = dv_dt -  D*(dv_dxx + dv_dyy) + k*V*(V-a)*(V-1) +W*V\n",
        "    eq_b = dw_dt -  (epsilon + (mu_1*W)/(mu_2+V))*(-W -k*V*(V-b-1))\n",
        "    return [eq_a, eq_b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6W_77Ftb5e-"
      },
      "source": [
        "We define:\n",
        "\n",
        "\n",
        "*   IC_func, taking the training data points near time zero as the initial conditions.\n",
        "*   BC_func, to employ the no-flux Neumann boundary condition. This is to prevent a leakage of V (potential) to regions outside the heart domain.\n",
        "\n",
        "We then split the loaded data randomly into a train and a test set using `train_test_split()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n1yYHA8hc8PQ"
      },
      "outputs": [],
      "source": [
        "# Initial and boundary conditions\n",
        "def IC_func(observe_train, v_train):\n",
        "\n",
        "    T_ic = observe_train[:,-1].reshape(-1,1)\n",
        "    idx_init = np.where(np.isclose(T_ic,0))[0]\n",
        "    v_init = v_train[idx_init]\n",
        "    observe_init = observe_train[idx_init]\n",
        "    print(np.shape(v_init))\n",
        "    print(np.shape(observe_init))\n",
        "    return dde.PointSetBC(observe_init,v_init,component=0)\n",
        "\n",
        "def boundary_func_2d(x, on_boundary):\n",
        "    return on_boundary and ~(x[0:2]==[min_x,min_y]).all() and  ~(x[0:2]==[min_x,max_y]).all() and ~(x[0:2]==[max_x,min_y]).all()  and  ~(x[0:2]==[max_x,max_y]).all()\n",
        "\n",
        "def BC_func(geomtime):\n",
        "    bc = dde.NeumannBC(geomtime, lambda x:  np.zeros((len(x), 1)), boundary_func_2d, component=0)\n",
        "    return bc\n",
        "\n",
        "\n",
        "observe_train, observe_test, v_train, v_test = train_test_split(observe_x,V,test_size=test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v18T45Z1dE_I"
      },
      "source": [
        "**Exercise**: define the geometry of the problem as before. Note that we have a 2D spatial geometry and a temporal interval in this problem.\n",
        "We also need to define the initial conditions for both equations and set up the experimental data for V."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "m19hOu63hVJt",
        "outputId": "40a3b474-3c53-49d0-e96b-957617b74e8f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dde' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7ab64e8c06b7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Complete the unfinished code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgeom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtimedomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeDomain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgeomtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeometryXTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dde' is not defined"
          ]
        }
      ],
      "source": [
        "# Complete the unfinished code\n",
        "geom = dde.geometry.Rectangle(...)\n",
        "timedomain = dde.geometry.TimeDomain(...)\n",
        "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
        "\n",
        "## Define Boundary Conditions\n",
        "bc = BC_func(geomtime)\n",
        "\n",
        "## Define Initial Conditions\n",
        "# Use the simulated data and the functions above\n",
        "ic1 = IC_func() # this is the initial condition for V\n",
        "ic2 = IC_func() # this is the initial condition for W,\n",
        "# which should be 0 everywhere\n",
        "\n",
        "## Include observed data as inputs to the network\n",
        "# We only have observed data for V\n",
        "observe_v = dde.PointSetBC(observe_train, v_train, component=0)\n",
        "input_data = [bc, ic1, ic2, observe_v]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVbhlTz1w8m-",
        "outputId": "0cad61cb-6041-41af-d151-1163134d9b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(894, 1)\n",
            "(894, 3)\n",
            "(894, 1)\n",
            "(894, 3)\n"
          ]
        }
      ],
      "source": [
        "# @title Solution\n",
        "geom = dde.geometry.Rectangle([min_x,min_y], [max_x,max_y])\n",
        "timedomain = dde.geometry.TimeDomain(min_t, max_t)\n",
        "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
        "\n",
        "## Define Boundary Conditions\n",
        "bc = BC_func(geomtime)\n",
        "\n",
        "## Define Initial Conditions\n",
        "ic1 = IC_func(observe_train, v_train)\n",
        "ic2 = IC_func(observe_train, np.zeros_like(v_train))\n",
        "\n",
        "## Include observed data as inputs to the network\n",
        "observe_v = dde.PointSetBC(observe_train, v_train, component=0)\n",
        "input_data = [bc, ic1, ic2, observe_v]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZG2OaGbbT4v"
      },
      "source": [
        "As before, we need to create\n",
        "\n",
        "*   net\n",
        "*   data\n",
        "\n",
        "And then combine then into a Model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V7MvwwmUNTwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "581d4d0c-7a9a-4c0c-978d-4fd6843547ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 39 points required, but 42 points sampled.\n",
            "Warning: 1000 points required, but 1092 points sampled.\n",
            "Compiling model...\n",
            "Building feed-forward neural network...\n",
            "'build' took 0.057322 s\n",
            "\n",
            "Warning: Rectangle boundary_normal called on vertices. You may use PDE(..., exclusions=...) to exclude the vertices.\n",
            "Warning: Rectangle boundary_normal called on vertices. You may use PDE(..., exclusions=...) to exclude the vertices.\n",
            "'compile' took 1.583571 s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Parameterisation\n",
        "input = 3\n",
        "num_hidden_layers = 3\n",
        "hidden_layer_size = 30\n",
        "num_domain = 40000\n",
        "num_boundary = 4000\n",
        "epochs_main = 150000\n",
        "output = 2\n",
        "out_path = 'AP1/'\n",
        "\n",
        "# Training Parameters\n",
        "num_domain = 20000 # number of training points within the domain\n",
        "num_boundary = 1000 # number of training boundary condition points on the geometry boundary\n",
        "num_test = 1000 # number of testing points within the domain\n",
        "MAX_MODEL_INIT = 5 # maximum number of times allowed to initialize the model\n",
        "MAX_LOSS = 0.1 # upper limit to the initialized loss\n",
        "epochs_init = 15000 # number of epochs for training initial phase\n",
        "epochs_main =400000 # number of epochs for main training phase\n",
        "lr = 0.0005 # learning rate\n",
        "test_size = 0.9 # split, fraction saved for test\n",
        "\n",
        "net = dde.maps.FNN([input] + [hidden_layer_size] * num_hidden_layers + [output], \"tanh\", \"Glorot uniform\")\n",
        "pde_data = dde.data.TimePDE(geomtime, pde, input_data,\n",
        "                            num_domain = num_domain,\n",
        "                            num_boundary=num_boundary,\n",
        "                            anchors=observe_train,\n",
        "                            num_test=num_test)\n",
        "model = dde.Model(pde_data, net)\n",
        "model.compile(\"adam\", lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0oq_2ryw8m-",
        "outputId": "7fd0f90e-f18f-4fcf-88c4-0a9c5a3acedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 39 points required, but 42 points sampled.\n",
            "Warning: 1000 points required, but 1092 points sampled.\n",
            "Compiling model...\n",
            "Building feed-forward neural network...\n",
            "'build' took 0.056052 s\n",
            "\n",
            "Warning: Rectangle boundary_normal called on vertices. You may use PDE(..., exclusions=...) to exclude the vertices.\n",
            "Warning: Rectangle boundary_normal called on vertices. You may use PDE(..., exclusions=...) to exclude the vertices.\n",
            "'compile' took 0.863254 s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Solution\n",
        "net = dde.maps.FNN([input] + [hidden_layer_size] * num_hidden_layers + [output], \"tanh\", \"Glorot uniform\")\n",
        "pde_data = dde.data.TimePDE(geomtime, pde, input_data,\n",
        "                            num_domain = num_domain,\n",
        "                            num_boundary=num_boundary,\n",
        "                            anchors=observe_train,\n",
        "                            num_test=num_test)\n",
        "model = dde.Model(pde_data, net)\n",
        "model.compile(\"adam\", lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCDiDoxQshcF"
      },
      "source": [
        "Here, we define a scheme to cap the initial loss from the network. We only allow the network to continue training if the initial loss is lower than a threshold. Otherwise, we will re-initialise the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "raf_TBksw8m-"
      },
      "outputs": [],
      "source": [
        "def stable_init(model):\n",
        "    ## Stabilize initialization process by capping the losses\n",
        "    losshistory, _ = model.train(epochs=1)\n",
        "    initial_loss = max(losshistory.loss_train[0])\n",
        "    num_init = 1\n",
        "    while initial_loss>MAX_LOSS or np.isnan(initial_loss):\n",
        "        num_init += 1\n",
        "        model = dde.Model(pde_data, net)\n",
        "        model.compile(\"adam\", lr=lr)\n",
        "        losshistory, _ = model.train(epochs=1)\n",
        "        initial_loss = max(losshistory.loss_train[0])\n",
        "        if num_init > MAX_MODEL_INIT:\n",
        "            raise ValueError('Model initialization phase exceeded the allowed limit')\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxvjvOSfs5r_"
      },
      "source": [
        "Now, let's customise a model training funtion with 3 phases:\n",
        "\n",
        "\n",
        "1.   train with data loss only, using Adam (Hint: use the `loss_weights` argument in `model.compile()` to set the other loss terms to zero.)\n",
        "2.   train with all loss terms, using Adam\n",
        "3.   train with all loss terms, using L-BFGS-B to help with convergence\n",
        "\n",
        "We then train the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "6t59Rn81s6LR",
        "outputId": "cd3ed572-030c-4c2f-8982-6930f3ae5e0b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-11-d3473b8404b2>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-d3473b8404b2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    init_weights = #...\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "def train_3_phase(out_path):\n",
        "    init_weights = #...\n",
        "\n",
        "    ## Initial phase with data term only\n",
        "    model.compile(\"adam\", lr=lr, loss_weights=init_weights)\n",
        "    losshistory, train_state = model.train(iterations=epochs_init, model_save_path = out_path)\n",
        "\n",
        "    ## Main phase with all terms\n",
        "\n",
        "\n",
        "    ## Final phase with L-BFGS-B\n",
        "\n",
        "\n",
        "    return losshistory, train_state\n",
        "\n",
        "def train_1_phase(out_path):\n",
        "    losshistory, train_state = model.train(iterations=10000, model_save_path = out_path)\n",
        "    return losshistory, train_state\n",
        "\n",
        "# stable_init(model)\n",
        "# losshistory, train_state = train_3_phases(model, out_path)\n",
        "losshistory, train_state = train_1_phase(out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADnWaKv4w8m_",
        "outputId": "a1ac5eca-4c1b-4985-da5f-7014212fa641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "\n",
            "Step      Train loss                                                      Test loss                                                       Test metric\n",
            "0         [2.92e+00, 1.82e+04, 2.15e-03, 5.41e-01, 5.41e-01, 3.83e-01]    [1.36e+00, 4.00e+03, 2.15e-03, 5.41e-01, 5.41e-01, 3.83e-01]    []  \n",
            "1000      [6.00e-01, 5.59e+01, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    [5.83e-01, 3.06e-02, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    []  \n",
            "2000      [6.08e-01, 4.48e+01, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    [5.92e-01, 2.64e-02, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    []  \n",
            "3000      [6.20e-01, 3.35e+01, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    [6.05e-01, 2.09e-02, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    []  \n",
            "4000      [6.36e-01, 2.22e+01, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    [6.22e-01, 1.48e-02, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    []  \n",
            "5000      [6.57e-01, 1.23e+01, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    [6.45e-01, 9.61e-03, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    []  \n",
            "6000      [6.79e-01, 5.46e+00, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    [6.69e-01, 6.71e-03, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    []  \n",
            "7000      [6.99e-01, 2.18e+00, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    [6.91e-01, 6.27e-03, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    []  \n",
            "8000      [7.11e-01, 1.24e+00, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    [7.03e-01, 6.92e-03, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    []  \n",
            "9000      [7.13e-01, 1.01e+00, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    [7.06e-01, 7.27e-03, 1.35e-03, 9.79e-02, 9.79e-02, 3.40e-01]    []  \n",
            "10000     [7.10e-01, 8.76e-01, 1.35e-03, 9.80e-02, 9.80e-02, 3.40e-01]    [7.02e-01, 7.22e-03, 1.35e-03, 9.80e-02, 9.80e-02, 3.40e-01]    []  \n",
            "\n",
            "Best model at step 10000:\n",
            "  train loss: 2.12e+00\n",
            "  test loss: 1.25e+00\n",
            "  test metric: []\n",
            "\n",
            "Epoch 10000: saving model to AP1/-10000.ckpt ...\n",
            "\n",
            "'train' took 265.308890 s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Solution\n",
        "def train_3_phase(out_path):\n",
        "    init_weights = [0,0,0,0,1]\n",
        "\n",
        "    ## Initial phase\n",
        "    model.compile(\"adam\", lr=lr, loss_weights=init_weights)\n",
        "    losshistory, train_state = model.train(iterations=epochs_init, model_save_path = out_path)\n",
        "    ## Main phase\n",
        "    model.compile(\"adam\", lr=lr)\n",
        "    losshistory, train_state = model.train(iterations=epochs_main, model_save_path = out_path)\n",
        "    ## Final phase\n",
        "    model.compile(\"L-BFGS-B\")\n",
        "    losshistory, train_state = model.train(model_save_path = out_path)\n",
        "    return losshistory, train_state\n",
        "\n",
        "def train_1_phase(out_path):\n",
        "    losshistory, train_state = model.train(iterations=10000, model_save_path = out_path)\n",
        "    return losshistory, train_state\n",
        "\n",
        "# stable_init(model)\n",
        "# losshistory, train_state = train_3_phases(model, out_path)\n",
        "losshistory, train_state = train_1_phase(out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUD9p7jBuCFi"
      },
      "source": [
        "After training, we can make predictions and check the RMSE for test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "v6TS9Fzyw8m_",
        "outputId": "761a7e3f-08f8-4bd5-b313-86ac11c937de"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bc371bb209c5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserve_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mv_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrmse_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"V RMSE for test data:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "pred = model.predict(observe_test)\n",
        "v_pred = pred[:,0:1]\n",
        "rmse_v = np.sqrt(np.square(v_pred - v_test).mean())\n",
        "print(\"V RMSE for test data:\", rmse_v)\n",
        "\n",
        "pred_2 = model.predict(observe_x)\n",
        "v_pred_model = pred_2[:,0:1]\n",
        "np.savetxt(\"v_pred_model_spiral.txt\",np.hstack((observe_x,v_pred_model)),header=\"observe_x, v_pred_model\")\n",
        "\n",
        "dicti = {'pred': pred,'observe_test': observe_test, 'observe_train': observe_train, 'pred_all': pred_2, 'observe_x': observe_x, 'rmse_v': rmse_v}\n",
        "scipy.io.savemat('out_path' + 'results.mat',dicti)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1VL_SHwuMYo"
      },
      "source": [
        "Visualing the results at a user-defined position."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "xYf8DYE5w8m_",
        "outputId": "f58894a7-b7ba-45a6-c168-4d6f96320ceb"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'observe_test' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fd3e0e2d075c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserve_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m163965\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserve_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserve_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'observe_test' is not defined"
          ]
        }
      ],
      "source": [
        "ind=observe_test[163965,0:2]\n",
        "print(ind[1])\n",
        "a=np.squeeze(np.isclose(observe_test[:,0:1],ind[0]))\n",
        "b=np.squeeze(np.isclose(observe_test[:,1:2],ind[1]))\n",
        "c=np.logical_and(a,b)\n",
        "plt.plot(observe_test[c,2],pred[c,1:2],'o',label='Test')\n",
        "\n",
        "a=np.squeeze(np.isclose(observe_x[:,0:1],ind[0]))\n",
        "b=np.squeeze(np.isclose(observe_x[:,1:2],ind[1]))\n",
        "c=np.logical_and(a,b)\n",
        "plt.plot(observe_x[c,1],vlin[c],'-',label='GT')\n",
        "\n",
        "plt.plot(observe_x[c,1],pred_2[c,1:2],':',label='Train and Test')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('V at x:' + str(ind[0]) + ', y:' + str(ind[1]))\n",
        "plt.ylabel('V (AU)')\n",
        "plt.xlabel('time (AU)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r__3LWHjN-Wb"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "PC_PINNs",
      "language": "python",
      "name": "pc_pinns"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}